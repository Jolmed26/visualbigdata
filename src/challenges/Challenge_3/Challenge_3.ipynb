{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUVxpOQBWLvO"
   },
   "source": [
    "# Challenge Avanzado: Análisis de Grandes Bases de Datos con PySpark, Relacionado a la Tesis\n",
    "\n",
    "## Contenido\n",
    "\n",
    "1. Fuentes de datos\n",
    "2. Descripción de los datos\n",
    "3. Limpieza de datos\n",
    "4. Valores faltantes\n",
    "5. Visualización de datos\n",
    "6. Referencias\n",
    "\n",
    "## 1. Fuentes de datos\n",
    "\n",
    "La fuente de datos de este trabajo es **estrucurada** en formato xlsx. Los datos son **privados** y se eliminó toda la información sensible por privacidad de los datos. Esta base de datos contiene información sobre rotación de personal de empresas manufactureras de Tala, Jalisco.\n",
    "\n",
    "Se trata de una base de datos transversal que comprende del 20 de abril del 2021 al 30 de abril del 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "N37mrgoUWGJ2",
    "outputId": "a3e49603-9a01-4920-cb93-6dba7a371acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se tienen  1 núcleo(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a99834ccc9fa:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>rotacion</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7c906346dc30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creamos una instancia de Pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark = SparkSession.builder.appName(\"TodlerAutism\").getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"rotacion\").master(\"local[*]\").config(\"spark.executor.memory\", \"2g\").config(\"spark.driver.memory\", \"2g\").getOrCreate()\n",
    "\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "\n",
    "print(\"Se tienen \", cores, \"núcleo(s)\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4Fds_UUWk5I"
   },
   "outputs": [],
   "source": [
    "# Librerías necesarias\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder # Aqui se incluye la parte de Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKyGVRU4WlxG"
   },
   "outputs": [],
   "source": [
    "# Importación de datos como spark DF\n",
    "df = spark.read.csv('rotacion_personal_clean.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HLFqRFUWwV6",
    "outputId": "397af0f2-9ce3-4695-b434-0d5819ee47d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FECHA DE INGRESO: date (nullable = true)\n",
      " |-- FECHA ULTIMO REGISTRO: date (nullable = true)\n",
      " |-- Estatus: string (nullable = true)\n",
      " |-- Días Laborados: integer (nullable = true)\n",
      " |-- FECHA DE NACIMIENTO: timestamp (nullable = true)\n",
      " |-- No de Crédito Infonavit: string (nullable = true)\n",
      " |-- PUESTO: string (nullable = true)\n",
      " |-- AREA: string (nullable = true)\n",
      " |-- TURNO: string (nullable = true)\n",
      " |-- MUNICIPIO: string (nullable = true)\n",
      " |-- SALARIO MENSUAL: double (nullable = true)\n",
      " |-- ESCOLARIDAD: string (nullable = true)\n",
      " |-- GENERO: string (nullable = true)\n",
      " |-- Tipo de renuncia: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-_y5ejoXntI"
   },
   "source": [
    "Para facilitar el análisis se renombran las columnas con títulos más adecuados y sin carácteres especiales ni espacios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "opTshKdmW8SN",
    "outputId": "b6b2aa6f-242f-4232-f017-c513b973032f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FECHA_INGRESO: date (nullable = true)\n",
      " |-- FECHA_ULTIMO_REGISTRO: date (nullable = true)\n",
      " |-- ESTATUS: string (nullable = true)\n",
      " |-- DIAS_LABORADOS: integer (nullable = true)\n",
      " |-- FECHA_NACIMIENTO: timestamp (nullable = true)\n",
      " |-- INFONAVIT: string (nullable = true)\n",
      " |-- PUESTO: string (nullable = true)\n",
      " |-- AREA: string (nullable = true)\n",
      " |-- TURNO: string (nullable = true)\n",
      " |-- MUNICIPIO: string (nullable = true)\n",
      " |-- SALARIO_MENSUAL: double (nullable = true)\n",
      " |-- ESCOLARIDAD: string (nullable = true)\n",
      " |-- GENERO: string (nullable = true)\n",
      " |-- MOTIVO_RENUNCIA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Renombramos variables\n",
    "df = df.withColumnRenamed(\"FECHA DE INGRESO\", \"FECHA_INGRESO\") \\\n",
    "       .withColumnRenamed(\"FECHA ULTIMO REGISTRO\", \"FECHA_ULTIMO_REGISTRO\") \\\n",
    "       .withColumnRenamed(\"Estatus\", \"ESTATUS\") \\\n",
    "       .withColumnRenamed(\"Días Laborados\", \"DIAS_LABORADOS\") \\\n",
    "       .withColumnRenamed(\"FECHA DE NACIMIENTO\", \"FECHA_NACIMIENTO\") \\\n",
    "       .withColumnRenamed(\"No de Crédito Infonavit\", \"INFONAVIT\") \\\n",
    "       .withColumnRenamed(\"PUESTO\", \"PUESTO\") \\\n",
    "       .withColumnRenamed(\"AREA\", \"AREA\") \\\n",
    "       .withColumnRenamed(\"TURNO\", \"TURNO\") \\\n",
    "       .withColumnRenamed(\"MUNICIPIO\", \"MUNICIPIO\") \\\n",
    "       .withColumnRenamed(\"SALARIO MENSUAL\", \"SALARIO_MENSUAL\") \\\n",
    "       .withColumnRenamed(\"ESCOLARIDAD\", \"ESCOLARIDAD\") \\\n",
    "       .withColumnRenamed(\"GENERO\", \"GENERO\") \\\n",
    "       .withColumnRenamed(\"Tipo de renuncia\", \"MOTIVO_RENUNCIA\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las variables con las que contamos las fechas no se pueden procesar en el modelo, así que antes de eliminarlas crearemos una nueva variable edad restando la fecha de nacimiento a la de corte de los datos 2024-04-30. \n",
    "\n",
    "También se eliminará la columna Motivo de renuncia ya que tiene muchos datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QIjNw56pYqay"
   },
   "outputs": [],
   "source": [
    "# Fecha de referencia para calcular la edad\n",
    "fecha_referencia = '2024-04-30'\n",
    "\n",
    "# Calcular la diferencia en días entre la fecha de nacimiento y la fecha de referencia\n",
    "df = df.withColumn(\n",
    "    \"EDAD\",\n",
    "    (F.datediff(F.lit(fecha_referencia), F.col(\"FECHA_NACIMIENTO\")) / 365.25).cast(\"int\")\n",
    ")\n",
    "\n",
    "# Eliminar la columna MOTIVO_RENUNCIA Y LAS DE FECHA\n",
    "df = df.drop(\"MOTIVO_RENUNCIA\", \"FECHA_INGRESO\", \"FECHA_ULTIMO_REGISTRO\", \"FECHA_NACIMIENTO\" )\n",
    "\n",
    "# Obtener la lista de las columnas actuales\n",
    "columns = df.columns\n",
    "\n",
    "# Mover ESTATUS al final\n",
    "columns.remove(\"ESTATUS\")\n",
    "columns.append(\"ESTATUS\")\n",
    "\n",
    "# Reordenar las columnas para que ESTATUS esté al final\n",
    "df = df.select(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uN_1LCMxXj-5",
    "outputId": "5cd0b132-b537-451f-9d0f-e1f1aec3d562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|ESTATUS|count|\n",
      "+-------+-----+\n",
      "|   baja|  425|\n",
      "| activo|   70|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variable objetivo\n",
    "df.groupBy(\"ESTATUS\").count().show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZ_xPOKBYEpO"
   },
   "outputs": [],
   "source": [
    "# Función de tratamiento de datos\n",
    "\n",
    "def df_treat(df,input_columns,target,treat_outliers=False,treat_neg=False):\n",
    "\n",
    "    # Puede ser que target no sea string\n",
    "    df_renamed = df.withColumn(\"label_str\",df[target].cast(StringType()))\n",
    "\n",
    "    # variable target string -> numeric/dummy/boolean/onehotencoder\n",
    "    indexer = StringIndexer(inputCol=\"label_str\",\n",
    "                            outputCol=\"label\") # por default pyspark target es \"label\"\n",
    "    df_indexed = indexer.fit(df_renamed).transform(df_renamed)\n",
    "    print(df_indexed.groupBy(\"ESTATUS\",\"label\").count().show())\n",
    "\n",
    "    # identificamos las variables categoricas y numericas\n",
    "    numeric_input =[]\n",
    "    string_input = []\n",
    "\n",
    "    for column in input_columns: # se va por cada variable\n",
    "        if str(df_indexed.schema[column].dataType)=='StringType()':\n",
    "            indexer = StringIndexer(inputCol=column,\n",
    "                                  outputCol=column+'_num') # funciond e indexeo\n",
    "            df_indexed = indexer.fit(df_indexed).transform(df_indexed)\n",
    "            new_col_name = column+'_num' # este nuevo nombre es el que se agrega a las listas vacías\n",
    "            string_input.append(new_col_name)\n",
    "        else:\n",
    "           numeric_input.append(column)\n",
    "\n",
    "    print(\"numeric_input:\", numeric_input)\n",
    "    print(\"string_input:\", string_input)\n",
    "\n",
    "    if treat_outliers:\n",
    "\n",
    "        d = {} #aqui vamos a guardar los percentiles 1 y 99\n",
    "\n",
    "        for col in numeric_input:\n",
    "            d[col] = df_indexed.approxQuantile(col,\n",
    "                                              [0.01,0.99],\n",
    "                                               0.25)\n",
    "    # checamos la asimetría de todas las columnas numéricas\n",
    "        for col in numeric_input:\n",
    "            skew = df_indexed.agg(skewness(df_indexed[col])).collect()\n",
    "            skew = skew[0][0]\n",
    "\n",
    "            if skew > 1: # si se tiene asimetría positiva, se hace tranformación log\n",
    "                df_indexed = df_indexed.withColumn(col,\n",
    "                                           log(when(df[col] < d[col][0],d[col][0]).when(df_indexed[col] > d[col][1], d[col][1]).otherwise(df_indexed[col] ) +1).alias(col))\n",
    "                print(\"La variable \"+col+\" ha sido tratada para asimetría positiva con coeficiente = \",skew)\n",
    "            elif skew < -1: # si se tiene asimetría negativa, se hace tranformación exp\n",
    "                df_indexed = df_indexed.withColumn(col,\n",
    "                                           exp(when(df[col] < d[col][0],d[col][0]).when(df_indexed[col] > d[col][1], d[col][1]).otherwise(df_indexed[col] ) +1).alias(col))\n",
    "                print(\"La variable \"+col+\" ha sido tratada para asimetría negativa con coeficiente = \",skew)\n",
    "\n",
    "    # Calculamos los valores minimos para todas las columnas del dataframe\n",
    "    minimums = df.select([min(c).alias(c) for c in df.columns if c in numeric_input])\n",
    "\n",
    "    # Creamos un array con todos los minimos y seleccionamos solo las columnas con valores de entrada\n",
    "    min_array = minimums.select(array(numeric_input).alias(\"mins\"))\n",
    "\n",
    "    # Lo siguiente es collectar los minimos globales como objeto en python\n",
    "    # aqui tambien se utiliza una funcion array_min en lugar de min, para spark sql\n",
    "    df_minimum = min_array.select(min(min_array.mins)).collect()\n",
    "\n",
    "    # Ahora tenemos que cortar lo anterior al número que necesitamos\n",
    "    df_minimum = df_minimum[0][0][0]\n",
    "\n",
    "    # Si hay algún valor negativo en el DF, se da un mensaje\n",
    "    if df_minimum < 0:\n",
    "        print(\"ATENCION: Existen valores negativos en el DataSet\")\n",
    "    else:\n",
    "        print(\"No se encuentran valores negativos en el DataSet\")\n",
    "\n",
    "    # vectorizar\n",
    "    # Antes de cooregir los valores negativos, se tiene que vectorizar lo que hemos hecho\n",
    "    features_list = numeric_input + string_input\n",
    "    # Creamos el objeto de VectorAssembler\n",
    "    assembler = VectorAssembler(inputCols=features_list,\n",
    "                                outputCol=\"features\")\n",
    "    # Utilizamos este assembler para trasformar los datos\n",
    "    df_output = assembler.transform(df_indexed).select(\"features\",'label')\n",
    "\n",
    "\n",
    "    if treat_neg:\n",
    "        # reescalar valores numéricos\n",
    "        scaler = MinMaxScaler(inputCol='features',\n",
    "                            outputCol=\"scaledFeatures\") #el vector que ya habiamos creado\n",
    "        print(\"Features escalados a un rango de: [%f,%f]\" % (scaler.getMin(), scaler.getMax()))\n",
    "\n",
    "        # Generar el modelo MinMaxScalerModel\n",
    "        scalerModel = scaler.fit(df_output)\n",
    "\n",
    "        # Reescalar cada feature al rango indicado\n",
    "        df_scaled = scalerModel.transform(df_output)\n",
    "\n",
    "        # DataFrame final\n",
    "        df_final = df_scaled.select('label','scaledFeatures')\n",
    "        df_final = df_final.withColumnRenamed('scaledFeatures','features')\n",
    "        print(\"Listo\")\n",
    "    else:\n",
    "        print(\"WARNING:No hay correcciones de valores negativos\")\n",
    "        df_final = df_output\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "VUlPzxWtYjKG",
    "outputId": "a0a6d63b-830f-4eba-a29f-7170bacf095d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|ESTATUS|label|count|\n",
      "+-------+-----+-----+\n",
      "|   baja|  0.0|  425|\n",
      "| activo|  1.0|   70|\n",
      "+-------+-----+-----+\n",
      "\n",
      "None\n",
      "numeric_input: ['SALARIO_MENSUAL', 'EDAD']\n",
      "string_input: ['INFONAVIT_num', 'PUESTO_num', 'AREA_num', 'TURNO_num', 'MUNICIPIO_num', 'ESCOLARIDAD_num', 'GENERO_num']\n",
      "La variable SALARIO_MENSUAL ha sido tratada para asimetría positiva con coeficiente =  2.9469329728756533\n",
      "No se encuentran valores negativos en el DataSet\n",
      "Features escalados a un rango de: [0.000000,1.000000]\n",
      "Listo\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 495,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.348800750812304,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"features\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 357,\n        \"samples\": [\n          \"(9,[1,5,8],[0.15555555555555556,0.6666666666666666,1.0])\",\n          \"(9,[0,1,2,7],[0.08675004776993307,0.6888888888888889,1.0,0.2727272727272727])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-af2b1e4e-96a2-495d-a50d-1db2d8f44cf3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.20310421602746923, 0.5777777777777778, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.20310421602746923, 0.26666666666666666, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.26666666666666666, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.20310421602746923, 0.06666666666666667, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.796878086847233, 0.22222222222222224, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.22773347223802257, 0.33333333333333337, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.22773347223802257, 0.33333333333333337, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.22773347223802257, 0.33333333333333337, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af2b1e4e-96a2-495d-a50d-1db2d8f44cf3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-af2b1e4e-96a2-495d-a50d-1db2d8f44cf3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-af2b1e4e-96a2-495d-a50d-1db2d8f44cf3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-184cf323-5859-40e0-a212-44a60c33e115\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-184cf323-5859-40e0-a212-44a60c33e115')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-184cf323-5859-40e0-a212-44a60c33e115 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "     label                                           features\n",
       "0      0.0  (0.20310421602746923, 0.5777777777777778, 1.0,...\n",
       "1      0.0  (0.20310421602746923, 0.26666666666666666, 0.0...\n",
       "2      0.0  (0.0, 0.26666666666666666, 0.0, 0.0, 0.0, 0.0,...\n",
       "3      0.0  (0.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.0,...\n",
       "4      0.0  (0.20310421602746923, 0.06666666666666667, 0.0...\n",
       "..     ...                                                ...\n",
       "490    1.0  (0.0, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0,...\n",
       "491    1.0  [0.796878086847233, 0.22222222222222224, 1.0, ...\n",
       "492    1.0  (0.22773347223802257, 0.33333333333333337, 0.0...\n",
       "493    1.0  [0.22773347223802257, 0.33333333333333337, 1.0...\n",
       "494    1.0  (0.22773347223802257, 0.33333333333333337, 0.0...\n",
       "\n",
       "[495 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_columns = df.columns[1:-1] # la última entrada es la variable objetivo\n",
    "target = \"ESTATUS\" # variable objetivo/dependiente\n",
    "\n",
    "# Llamamos la función de tratamiento de datos\n",
    "df_final = df_treat(df=df,\n",
    "                      input_columns=input_columns,\n",
    "                      target=target,\n",
    "                      treat_outliers=True,\n",
    "                      treat_neg=True)\n",
    "\n",
    "df_final.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_uD7L-lbS9L"
   },
   "outputs": [],
   "source": [
    "# Función de modelos de clasificación \n",
    "\n",
    "def ClassTrainEval(classifier,features,classes,folds,train,test):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "\n",
    "        return Mtype\n",
    "\n",
    "    Mtype = FindMtype(classifier)\n",
    "\n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features,folds,train):\n",
    "\n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # Inicializar modelo base para clasificación\n",
    "            lr = LogisticRegression()\n",
    "            # Inicializar one vs rest classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "#             fitModel = OVRclassifier.fit(train)\n",
    "            # Parametros de validacion cruzada:\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "                .build()\n",
    "            # Inicializar validación cruzada\n",
    "            crossval = CrossValidator(estimator=OVRclassifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=folds)\n",
    "            # Se realiza la validación cruzada y se regresa el mejor set de parámetros\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # se especifican las capas de la red neuronal\n",
    "            # Capa de entrada de características de tamaño, dos intermedias de características +1 y del mismo tamaño que las características y salida de tamaño número de clases\n",
    "            # Nota: validacion cruzada no puede utilizarse aquí\n",
    "            features_count = len(features[0][0])\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: # These classifiers currently only accept binary classification\n",
    "            print(Mtype,\" Los algoritmos utilizados no pueden utilizarse pues son para clasificación binaria\")\n",
    "            return\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "\n",
    "            # Cambiar los parametros de cada modelo:\n",
    "            if Mtype in(\"LogisticRegression\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                             .build())\n",
    "\n",
    "            if Mtype in(\"NaiveBayes\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "                             .build())\n",
    "\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "                             .build())\n",
    "\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "                             .build())\n",
    "\n",
    "            if Mtype in(\"LinearSVC\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .build())\n",
    "\n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100, 120, 140, 160, 180, 200, 220, 240]) \\\n",
    "                             .build())\n",
    "\n",
    "            # Se inicializa validación cruzada\n",
    "            crossval = CrossValidator(estimator=classifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=folds) # 3 + is best practice\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "\n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,folds,train)\n",
    "\n",
    "    # se imprime la selección de features\n",
    "    if fitModel is not None:\n",
    "\n",
    "        if Mtype in(\"OneVsRest\"):\n",
    "            # Tomar el mejor modelo\n",
    "            BestModel = fitModel.bestModel\n",
    "            global OVR_BestModel\n",
    "            OVR_BestModel = BestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            # Modelos binarios\n",
    "            models = BestModel.models\n",
    "            for model in models:\n",
    "                print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept)\n",
    "                print('\\033[1m' + 'Top 20 Coefficients:'+ '\\033[0m')\n",
    "                coeff_array = model.coefficients.toArray()\n",
    "                coeff_scores = []\n",
    "                for x in coeff_array:\n",
    "                    coeff_scores.append(float(x))\n",
    "                # Se crea un nuevo df\n",
    "                result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\n",
    "                print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\n",
    "\n",
    "\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            print(\"\")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "            print(\"\")\n",
    "            global MLPC_Model\n",
    "            MLPC_BestModel = fitModel\n",
    "\n",
    "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\n",
    "            # Importancia de las variables de entrada\n",
    "            # Se realiza como la media sobre todos los árboles en el ensamble, normalizado a 1.\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Top 20 Feature Importances\"+ '\\033[0m')\n",
    "            print(\"(Scores add up to 1)\")\n",
    "            print(\"Lowest score is the least important\")\n",
    "            print(\" \")\n",
    "            featureImportances = BestModel.featureImportances.toArray()\n",
    "            # numpy array to list\n",
    "            imp_scores = []\n",
    "            for x in featureImportances:\n",
    "                imp_scores.append(float(x))\n",
    "            # Zip\n",
    "            result = spark.createDataFrame(zip(input_columns,imp_scores), schema=['feature','score'])\n",
    "            print(result.orderBy(result[\"score\"].desc()).show(truncate=False))\n",
    "\n",
    "            # Se guardan las importancias de los modelos\n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                global DT_featureimportances\n",
    "                DT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global DT_BestModel\n",
    "                DT_BestModel = BestModel\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                global GBT_featureimportances\n",
    "                GBT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global GBT_BestModel\n",
    "                GBT_BestModel = BestModel\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                global RF_featureimportances\n",
    "                RF_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global RF_BestModel\n",
    "                RF_BestModel = BestModel\n",
    "\n",
    "        # Se imprimen los coeficientes\n",
    "        if Mtype in(\"LogisticRegression\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "            print('\\033[1m' + \" Top 20 Coefficients\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            # numpy array to list\n",
    "            coeff_array = BestModel.coefficientMatrix.toArray()\n",
    "            coeff_scores = []\n",
    "            for x in coeff_array[0]:\n",
    "                coeff_scores.append(float(x))\n",
    "            # zip\n",
    "            result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\n",
    "            print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\n",
    "            # Se guardan los coeficientes y valores de los modelos\n",
    "            global LR_coefficients\n",
    "            LR_coefficients = BestModel.coefficientMatrix.toArray()\n",
    "            global LR_BestModel\n",
    "            LR_BestModel = BestModel\n",
    "\n",
    "        # Se imprimen los coeficientes\n",
    "        if Mtype in(\"LinearSVC\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            print(\"Intercept: \" + str(BestModel.intercept))\n",
    "            print('\\033[1m' + \"Top 20 Coefficients\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "#             print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "            coeff_array = BestModel.coefficients.toArray()\n",
    "            coeff_scores = []\n",
    "            for x in coeff_array:\n",
    "                coeff_scores.append(float(x))\n",
    "            # zip\n",
    "            result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\n",
    "            print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\n",
    "            # Se guardan los coeficientes y valores de los modelos\n",
    "            global LSVC_coefficients\n",
    "            LSVC_coefficients = BestModel.coefficients.toArray()\n",
    "            global LSVC_BestModel\n",
    "            LSVC_BestModel = BestModel\n",
    "\n",
    "\n",
    "    # Match entre resultados y nombres de columnas, que se juntaran mas adelante:\n",
    "    columns = ['Classifier', 'Result']\n",
    "\n",
    "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
    "        Mtype = [Mtype] # lista\n",
    "        score = [\"N/A\"]\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    else:\n",
    "        predictions = fitModel.transform(test)\n",
    "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "        Mtype = [Mtype] # string\n",
    "        score = [str(accuracy)] #string to list\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "\n",
    "    return result\n",
    "    #También regresa el mejor modelo y pvalores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMLEmmN5bbWt",
    "outputId": "5af0b3a6-c5d6-4f14-df95-87e10e87fc71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|ESTATUS|label|count|\n",
      "+-------+-----+-----+\n",
      "|   baja|  0.0|  425|\n",
      "| activo|  1.0|   70|\n",
      "+-------+-----+-----+\n",
      "\n",
      "None\n",
      "numeric_input: ['SALARIO_MENSUAL']\n",
      "string_input: ['PUESTO_num', 'AREA_num', 'TURNO_num', 'MUNICIPIO_num', 'ESCOLARIDAD_num', 'GENERO_num']\n",
      "No se encuentran valores negativos en el DataSet\n",
      "WARNING:No hay correcciones de valores negativos\n",
      " \n",
      "\u001b[1mLogisticRegression\u001b[0m\n",
      "Intercept: [-3.11285748834446]\n",
      "\u001b[1m Top 20 Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "+---------------+---------------------+\n",
      "|feature        |coeff                |\n",
      "+---------------+---------------------+\n",
      "|AREA           |0.8779519420801623   |\n",
      "|MUNICIPIO      |0.14399844787456878  |\n",
      "|SALARIO_MENSUAL|0.05786109980013657  |\n",
      "|PUESTO         |2.0744941922979553E-4|\n",
      "|ESCOLARIDAD    |-0.05590397994692011 |\n",
      "|GENERO         |-0.6433385030510809  |\n",
      "|TURNO          |-1.1160111064659852  |\n",
      "+---------------+---------------------+\n",
      "\n",
      "None\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m 2.3896296563749555\n",
      "\u001b[1mTop 20 Coefficients:\u001b[0m\n",
      "+---------------+--------------------+\n",
      "|feature        |coeff               |\n",
      "+---------------+--------------------+\n",
      "|GENERO         |0.25620021129842707 |\n",
      "|TURNO          |0.034313391725498806|\n",
      "|ESCOLARIDAD    |0.02676787090600292 |\n",
      "|PUESTO         |-8.61432531013303E-5|\n",
      "|SALARIO_MENSUAL|-0.05946783316160693|\n",
      "|AREA           |-0.06073864364305592|\n",
      "|MUNICIPIO      |-0.0812615930636148 |\n",
      "+---------------+--------------------+\n",
      "\n",
      "None\n",
      "\u001b[1mIntercept: \u001b[0m -2.3896296563749564\n",
      "\u001b[1mTop 20 Coefficients:\u001b[0m\n",
      "+---------------+---------------------+\n",
      "|feature        |coeff                |\n",
      "+---------------+---------------------+\n",
      "|MUNICIPIO      |0.0812615930636143   |\n",
      "|AREA           |0.06073864364305596  |\n",
      "|SALARIO_MENSUAL|0.05946783316160681  |\n",
      "|PUESTO         |8.614325310133044E-5 |\n",
      "|ESCOLARIDAD    |-0.026767870906002904|\n",
      "|TURNO          |-0.03431339172549881 |\n",
      "|GENERO         |-0.25620021129842746 |\n",
      "+---------------+---------------------+\n",
      "\n",
      "None\n",
      " \n",
      "\u001b[1mLinearSVC\u001b[0m\n",
      "Intercept: -1.013892967396146\n",
      "\u001b[1mTop 20 Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "+---------------+----------------------+\n",
      "|feature        |coeff                 |\n",
      "+---------------+----------------------+\n",
      "|AREA           |1.4132668063881915E-4 |\n",
      "|MUNICIPIO      |1.1341885268896233E-4 |\n",
      "|PUESTO         |2.0021558387054677E-6 |\n",
      "|ESCOLARIDAD    |0.0                   |\n",
      "|GENERO         |-0.0019974010224494162|\n",
      "|TURNO          |-0.002751555848827332 |\n",
      "|SALARIO_MENSUAL|-0.011788513915436793 |\n",
      "+---------------+----------------------+\n",
      "\n",
      "None\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Top 20 Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "+---------------+-------------------+\n",
      "|feature        |score              |\n",
      "+---------------+-------------------+\n",
      "|PUESTO         |0.3097975340715648 |\n",
      "|ESCOLARIDAD    |0.26392885438776725|\n",
      "|MUNICIPIO      |0.1329397763827751 |\n",
      "|AREA           |0.11993659674772436|\n",
      "|TURNO          |0.06980069711203488|\n",
      "|SALARIO_MENSUAL|0.05702495330723739|\n",
      "|GENERO         |0.04657158799089639|\n",
      "+---------------+-------------------+\n",
      "\n",
      "None\n",
      " \n",
      "\u001b[1mGBTClassifier  Top 20 Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "+---------------+-------------------+\n",
      "|feature        |score              |\n",
      "+---------------+-------------------+\n",
      "|MUNICIPIO      |0.2730014887094737 |\n",
      "|ESCOLARIDAD    |0.2355636376708327 |\n",
      "|PUESTO         |0.22732317317624565|\n",
      "|AREA           |0.15346332704132698|\n",
      "|SALARIO_MENSUAL|0.07310767135886306|\n",
      "|GENERO         |0.03754070204325816|\n",
      "|TURNO          |0.0                |\n",
      "+---------------+-------------------+\n",
      "\n",
      "None\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 143\n",
      "\n",
      "!!!!!Resultados finales!!!!!!!!\n",
      "+------------------------------+---------+\n",
      "|Classifier                    |Resultado|\n",
      "+------------------------------+---------+\n",
      "|LogisticRegression            |87.5     |\n",
      "|OneVsRest                     |87.5     |\n",
      "|LinearSVC                     |87.5     |\n",
      "|NaiveBayes                    |85.29    |\n",
      "|RandomForestClassifier        |84.55    |\n",
      "|GBTClassifier                 |86.02    |\n",
      "|MultilayerPerceptronClassifier|87.5     |\n",
      "+------------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_columns = input_columns[1:-1] # la última entrada es la variable objetivo\n",
    "target = 'ESTATUS' # variable objetivo\n",
    "estatus_count = df.select(countDistinct(\"ESTATUS\")).collect() #Cuenta valors únicos en la variable objetivo\n",
    "estatuses = estatus_count[0][0] # Buscamos el valor total del conteo\n",
    "\n",
    "\n",
    "# Llamamos a la funcion para tratamiento de datos\n",
    "test1_data = df_treat(df,input_columns,target,treat_outliers=False,treat_neg=False)\n",
    "test1_data.limit(5).toPandas()\n",
    "\n",
    "# Modelos a utilizar\n",
    "classifiers = [\n",
    "               LogisticRegression()\n",
    "              ,OneVsRest()\n",
    "              ,LinearSVC()\n",
    "              ,NaiveBayes()\n",
    "              ,RandomForestClassifier()\n",
    "              ,GBTClassifier()\n",
    "              ,DecisionTreeClassifier()\n",
    "              ,MultilayerPerceptronClassifier()\n",
    "              ]\n",
    "\n",
    "train,test = test1_data.randomSplit([0.7,0.3])\n",
    "features = test1_data.select(['features']).collect()\n",
    "folds = 2\n",
    "\n",
    "#Tabla de resultados\n",
    "columns = ['Classifier', 'Resultado']\n",
    "vals = [(\"Place Holder\",\"N/A\")]\n",
    "results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "# Llamamos la función de clasificación\n",
    "for classifier in classifiers:\n",
    "    new_result = ClassTrainEval(classifier,features,estatuses,folds,train,test)\n",
    "    results = results.union(new_result)\n",
    "results = results.where(\"Classifier!='Place Holder'\")\n",
    "print(\"!!!!!Resultados finales!!!!!!!!\")\n",
    "results.show(100,False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
